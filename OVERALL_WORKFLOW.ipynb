{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**THIS IS NEED TO BE INSTALLED FOR USING OUR ROBOFLOW MODEL!!**"
      ],
      "metadata": {
        "id": "yjlcELin5Sfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwRChmfr5MoE"
      },
      "outputs": [],
      "source": [
        "# Install Roboflow Inference SDK\n",
        "!pip install inference-sdk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "QdHCxO9L5keY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyBp4rx0mN65nLJxAJIsphq8DEw7odPaic0\")"
      ],
      "metadata": {
        "id": "QCBfDUa95lLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.0-pro-exp-02-05\"] {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "rmOn4WwK5wT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    types.SafetySetting(\n",
        "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        threshold=\"BLOCK_ONLY_HIGH\",\n",
        "    ),\n",
        "]\n",
        "bounding_box_system_instructions = \"\"\"\n",
        "   Return bounding boxes for detected (Images) in a newspaper as a JSON array with labels.\n",
        "\n",
        "      \"\"\"\n"
      ],
      "metadata": {
        "id": "0AjjSrvS5ysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "mQ03yyQ251MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Util**"
      ],
      "metadata": {
        "id": "w99iCXnk6cV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plotting Util\n",
        "\n",
        "# Get Noto JP font to display janapese characters\n",
        "# !apt-get install fonts-noto-cjk  # For Noto Sans CJK JP\n",
        "\n",
        "# !apt-get install fonts-source-han-sans-jp # For Source Han Sans (Japanese)\n",
        "\n",
        "import json\n",
        "import random\n",
        "import io\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from PIL import ImageColor\n",
        "output_dir=\"cropped_images\"\n",
        "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
        "\n",
        "def plot_bounding_boxes(im, bounding_boxes):\n",
        "    \"\"\"\n",
        "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
        "\n",
        "    Args:\n",
        "        img_path: The path to the image file.\n",
        "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
        "         and their positions in normalized [y1 x1 y2 x2] format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the image\n",
        "    img = im\n",
        "    width, height = img.size\n",
        "    print(img.size)\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Define a list of colors\n",
        "    colors = [\n",
        "    'red',\n",
        "    'green',\n",
        "    'blue',\n",
        "    'yellow',\n",
        "    'orange',\n",
        "    'pink',\n",
        "    'purple',\n",
        "    'brown',\n",
        "    'gray',\n",
        "    'beige',\n",
        "    'turquoise',\n",
        "    'cyan',\n",
        "    'magenta',\n",
        "    'lime',\n",
        "    'navy',\n",
        "    'maroon',\n",
        "    'teal',\n",
        "    'olive',\n",
        "    'coral',\n",
        "    'lavender',\n",
        "    'violet',\n",
        "    'gold',\n",
        "    'silver',\n",
        "    ] + additional_colors\n",
        "\n",
        "    # Parsing out the markdown fencing\n",
        "    bounding_boxes = parse_json(bounding_boxes)\n",
        "\n",
        "    # font = ImageFont.truetype(\"NotoSansCJK-Regular.ttc\", size=14)\n",
        "\n",
        "    # Iterate over the bounding boxes\n",
        "    for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
        "      # Select a color from the list\n",
        "      color = colors[i % len(colors)]\n",
        "\n",
        "      # Convert normalized coordinates to absolute coordinates\n",
        "      abs_y1 = int(bounding_box[\"box_2d\"][0]/1000 * height)\n",
        "      abs_x1 = int(bounding_box[\"box_2d\"][1]/1000 * width)\n",
        "      abs_y2 = int(bounding_box[\"box_2d\"][2]/1000 * height)\n",
        "      abs_x2 = int(bounding_box[\"box_2d\"][3]/1000 * width)\n",
        "      os.makedirs(output_dir, exist_ok=True)\n",
        "      img_array = np.array(img)\n",
        "      if abs_x1 > abs_x2:\n",
        "        abs_x1, abs_x2 = abs_x2, abs_x1\n",
        "\n",
        "      if abs_y1 > abs_y2:\n",
        "        abs_y1, abs_y2 = abs_y2, abs_y1\n",
        "      cropped_img_array = img_array[abs_y1:abs_y2, abs_x1:abs_x2]\n",
        "\n",
        "    # Convert back to PIL image\n",
        "      cropped_img = Image.fromarray(cropped_img_array)\n",
        "      file_path = os.path.join(output_dir, f\"{i}.png\")\n",
        "      cropped_img.save(file_path)\n",
        "\n",
        "      # Draw the bounding box\n",
        "      draw.rectangle(\n",
        "          ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
        "      )\n",
        "\n",
        "      # Draw the text\n",
        "      if \"label\" in bounding_box:\n",
        "        draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color)\n",
        "\n",
        "    # Display the image\n",
        "    img.show()"
      ],
      "metadata": {
        "id": "OLaIHWkq6Mjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parsing JSON output**"
      ],
      "metadata": {
        "id": "F3EHW3_R6lEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Parsing JSON output\n",
        "def parse_json(json_output):\n",
        "    # Parsing out the markdown fencing\n",
        "    lines = json_output.splitlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if line == \"```json\":\n",
        "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
        "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
        "            break  # Exit the loop once \"```json\" is found\n",
        "    return json_output\n",
        "\n",
        "import json\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_text(content):\n",
        "    # Remove newline characters and extra spaces\n",
        "    content = re.sub(r'\\n+', ' ', content)\n",
        "\n",
        "    # Remove unnecessary symbols like asterisks (*)\n",
        "    content = re.sub(r'\\*+', '', content)\n",
        "\n",
        "    # Normalize multiple spaces to a single space\n",
        "    content = re.sub(r'\\s+', ' ', content).strip()\n",
        "\n",
        "    return content\n",
        "\n",
        "\n",
        "def generate_speech(content, output_path=\"Voice/speech.mp3\", voice=\"onyx\"):\n",
        "    \"\"\"Generates speech from text using OpenAI's TTS model.\"\"\"\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"API key not found. Set OPENAI_API_KEY in environment variables.\")\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    cleaned_content = clean_text(content)  # Clean the text before TTS\n",
        "    response = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=voice,\n",
        "        input=cleaned_content,\n",
        "    )\n",
        "\n",
        "    response.stream_to_file(output_path)\n",
        "    print(f\"Audio saved at {output_path}\")"
      ],
      "metadata": {
        "id": "TvKuRPTh6jDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROPOSED SYSTEM 1**"
      ],
      "metadata": {
        "id": "XXEoCIby64Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "import PIL.Image\n",
        "import json\n",
        "cropped_images_dir = \"cropped_images\"\n",
        "if os.path.exists(cropped_images_dir):\n",
        "    # Delete all files inside the folder\n",
        "    for file in os.listdir(cropped_images_dir):\n",
        "        file_path = os.path.join(cropped_images_dir, file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "else:\n",
        "    print(\"Folder does not exist. Continuing execution...\")\n",
        "\n",
        "# Define the file name\n",
        "file_name = \"output.json\"\n",
        "\n",
        "# Write the string to a JSON file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Upload the image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "for filename in uploaded.keys():\n",
        "    image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Get the first uploaded file's name\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Get the full path\n",
        "image_path = os.path.join(\"/content\", filename)\n",
        "\n",
        "print(\"Uploaded image path:\", image_path)\n",
        "image = image_path\n",
        "prompt = \"Identify the positions of the photos in the newspaper \"\n",
        "\n",
        "# Load and resize image\n",
        "im = Image.open(image)\n",
        "# im.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
        "\n",
        "# Run model to find bounding boxes\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[prompt, im],\n",
        "    config = types.GenerateContentConfig(\n",
        "        system_instruction=bounding_box_system_instructions,\n",
        "        temperature=0.5\n",
        "    )\n",
        ")\n",
        "\n",
        "# Check output\n",
        "# print(response.text)\n",
        "\n",
        "# Generate image with bounding boxes\n",
        "plot_bounding_boxes(im, response.text)\n",
        "im\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image = PIL.Image.open(image)\n",
        "\n",
        "# client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[\"Extract text from the image \", image])\n",
        "\n",
        "# print(response.text)\n",
        "with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(response.text)\n",
        "print(\"Text extraction completed and saved to extracted_text.txt\")\n",
        "with open(\"extracted_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text_content = file.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[\"Start with intense or motivational military dialogue suitable for the article only one(Note: don't try to mention Military Dialogue only the dialogue should be shown on top for a good start ).Analyze the summarized news article with a focus on political consequences and future predictions. Present with short key points.Also represent this result like you are the AI news reporter\", text_content])\n",
        "descriptions = {}\n",
        "# print(response.text)\n",
        "descriptions[\"content\"]=response.text\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image, ImageDraw\n",
        "import google.generativeai as genai\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# Directory containing cropped images\n",
        "cropped_images_dir = \"cropped_images\"\n",
        "i=0\n",
        "# Load and process each image\n",
        "for image_file in os.listdir(cropped_images_dir):\n",
        "    image_path = os.path.join(cropped_images_dir, image_file)\n",
        "\n",
        "    # Open Image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Generate content for the image\n",
        "    response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[f\"Generate short description (content) for the image from the given data for the image {text_content} also check i don't need any bpunding box informations \", image])\n",
        "\n",
        "    # Get the response text\n",
        "    if response.text:\n",
        "        description = response.text.strip()\n",
        "    else:\n",
        "        description = \"No description generated.\"\n",
        "    descriptions[f'img{i}']=description\n",
        "    # Plot Image with Description\n",
        "    i+=1\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(description, fontsize=10, wrap=True)\n",
        "    plt.show()\n",
        "with open(file_name, \"w\") as json_file:\n",
        "      json.dump(descriptions, json_file, indent=4)\n",
        "\n",
        "print(\"Content stored successfully in output.json\")\n",
        "json_file = \"output.json\"  # Ensure this file exists in Colab\n",
        "data = load_json(json_file)\n",
        "cleaned_content = clean_text(data['content'])\n",
        "generate_speech(cleaned_content)\n"
      ],
      "metadata": {
        "id": "BhdG0Hpl6p6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q"
      ],
      "metadata": {
        "id": "6UJMTZ177FGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "E9aMjh-H7IqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "7e_yiP1Y7JXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}